{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantichar==0.2 in /home/keerthiv/.local/lib/python3.8/site-packages (0.2)\n",
      "Requirement already satisfied: Pillow in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (9.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (1.3.2)\n",
      "Requirement already satisfied: numpy in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (1.24.4)\n",
      "Requirement already satisfied: wandb in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (0.17.7)\n",
      "Requirement already satisfied: regex in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (2024.7.24)\n",
      "Requirement already satisfied: einops in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (0.8.0)\n",
      "Requirement already satisfied: ftfy in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (6.2.3)\n",
      "Requirement already satisfied: iopath in /home/keerthiv/.local/lib/python3.8/site-packages (from semantichar==0.2) (0.1.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from scikit-learn->semantichar==0.2) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from scikit-learn->semantichar==0.2) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from scikit-learn->semantichar==0.2) (1.4.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (8.1.7)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb->semantichar==0.2) (45.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (4.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (2.32.3)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (2.13.0)\n",
      "Requirement already satisfied: setproctitle in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (4.12.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.12.0; python_version < \"3.9\" and sys_platform == \"linux\" in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (5.27.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb->semantichar==0.2) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from wandb->semantichar==0.2) (5.3.1)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/keerthiv/.local/lib/python3.8/site-packages (from ftfy->semantichar==0.2) (0.2.13)\n",
      "Requirement already satisfied: tqdm in /home/keerthiv/.local/lib/python3.8/site-packages (from iopath->semantichar==0.2) (4.66.5)\n",
      "Requirement already satisfied: portalocker in /home/keerthiv/.local/lib/python3.8/site-packages (from iopath->semantichar==0.2) (2.10.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->semantichar==0.2) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb->semantichar==0.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->semantichar==0.2) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/keerthiv/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb->semantichar==0.2) (3.3.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->semantichar==0.2) (4.0.11)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->semantichar==0.2) (1.14.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->semantichar==0.2) (5.0.1)\n",
      "Requirement already satisfied: pillow==9.2.0 in /home/keerthiv/.local/lib/python3.8/site-packages (9.2.0)\n",
      "Object \"install\" is unknown, try \"ip help\".\n",
      "Requirement already satisfied: einops in /home/keerthiv/.local/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: iopath in /home/keerthiv/.local/lib/python3.8/site-packages (0.1.10)\n",
      "Requirement already satisfied: regex in /home/keerthiv/.local/lib/python3.8/site-packages (2024.7.24)\n",
      "Requirement already satisfied: wandb in /home/keerthiv/.local/lib/python3.8/site-packages (0.17.7)\n",
      "Requirement already satisfied: tqdm in /home/keerthiv/.local/lib/python3.8/site-packages (from iopath) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /home/keerthiv/.local/lib/python3.8/site-packages (from iopath) (4.12.2)\n",
      "Requirement already satisfied: portalocker in /home/keerthiv/.local/lib/python3.8/site-packages (from iopath) (2.10.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (45.2.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (2.13.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.12.0; python_version < \"3.9\" and sys_platform == \"linux\" in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (5.27.3)\n",
      "Requirement already satisfied: setproctitle in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: platformdirs in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/keerthiv/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: urllib3>=1.26.11 in /home/keerthiv/.local/lib/python3.8/site-packages (from sentry-sdk>=1.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/keerthiv/.local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.14.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/keerthiv/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install semantichar==0.2\n",
    "!pip install pillow==9.2.0\n",
    "!ip install ftfy\n",
    "!pip install einops iopath regex wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/xiyuanzh/SHARE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keerthiv/HAR_models/share/share_rasppi/SHARE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keerthiv/.local/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ./SHARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir model\n",
    "mkdir dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./easy_imu_phone.zip\n",
      "   creating: ./easy_imu_phone/\n",
      "  inflating: ./easy_imu_phone/y_train.npy  \n",
      "  inflating: ./easy_imu_phone/y_test.npy  \n",
      "  inflating: ./easy_imu_phone/x_test.npy  \n",
      "  inflating: ./easy_imu_phone/process.py  \n",
      "  inflating: ./easy_imu_phone/x_train.npy  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./easy_imu_phone.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keerthiv/HAR_models/share/share_rasppi/SHARE/src\n"
     ]
    }
   ],
   "source": [
    "cd ./src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from semantichar.utils import all_label_augmentation\n",
    "\n",
    "def DataBatch(data, label, text, l, batchsize, shuffle=True):\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    print( n )\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(n)\n",
    "    else:\n",
    "        index = np.arange(n)\n",
    "    for i in range(int(np.ceil(n/batchsize))):\n",
    "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
    "        yield inds, data[inds], label[inds], text[inds], l[inds]\n",
    "        \n",
    "def trainer(opt, \n",
    "            enc, \n",
    "            dec, \n",
    "            cross_entropy, \n",
    "            optimizer, \n",
    "            tr_data, \n",
    "            tr_label, \n",
    "            tr_text, \n",
    "            len_text, \n",
    "            break_step, \n",
    "            vocab_size, \n",
    "            device\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    Args:\n",
    "        opt: user-specified configurations.\n",
    "        enc: encoder of the model.\n",
    "        dec: decoder of the model.\n",
    "        cross_entropy: loss function.\n",
    "        optimizer: optimizer (default is Adam).\n",
    "        tr_data, tr_label, tr_text, len_text: training data, label, label sequence, length of the label sequence. \n",
    "        break_step: length of the longest label sequence length (i.e., maximum decoding step).\n",
    "        vocab_size: label name vocabulary size.\n",
    "        device: cuda or cpu.\n",
    "    \"\"\"\n",
    "\n",
    "    enc.train()\n",
    "    dec.train()  \n",
    "\n",
    "    total_loss = 0\n",
    "    for inds,batch_data, batch_label, batch_text, batch_len in \\\n",
    "        DataBatch(tr_data, tr_label, tr_text, len_text, opt['batchSize'],shuffle=True):\n",
    "        \n",
    "        batch_text = all_label_augmentation(batch_text, opt['prob'], break_step, vocab_size)\n",
    "\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_label = batch_label.to(device)\n",
    "        batch_text = batch_text.to(device)\n",
    "        batch_len = batch_len.to(device)\n",
    "\n",
    "        enc_hidden = enc(batch_data)\n",
    "        pred, batch_text_sorted, decode_lengths, sort_ind \\\n",
    "            = dec(enc_hidden, batch_text, batch_len)\n",
    "        \n",
    "        targets = batch_text_sorted[:, 1:]\n",
    "\n",
    "        pred, *_ = pack_padded_sequence(pred, decode_lengths, batch_first=True)\n",
    "        targets, *_ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "\n",
    "        loss = cross_entropy(pred, targets.long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += len(batch_data) * loss.item()\n",
    "\n",
    "    total_loss /= len(tr_data)\n",
    "    \n",
    "    return total_loss \n",
    "\n",
    "  \n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import os\n",
    "\n",
    "def evaluate(opt, \n",
    "             enc, \n",
    "             dec, \n",
    "             test_data, \n",
    "             test_label, \n",
    "             test_text, \n",
    "             test_len_text, \n",
    "             pred_dict, \n",
    "             seqs, \n",
    "             break_step, \n",
    "             class_num, \n",
    "             vocab_size, \n",
    "             device,\n",
    "             load=True):\n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    Args:\n",
    "        opt: user-specified configurations.\n",
    "        enc: encoder of the model.\n",
    "        dec: decoder of the model.\n",
    "        test_data, test_label, test_text, test_len_text: test data, label, label sequence, length of the label sequence.\n",
    "        pred_dict: mapping from label token-id sequence to label id.\n",
    "        seqs: label token-id sequence for all classes.\n",
    "        break_step: length of the longest label sequence length (i.e., maximum decoding step).\n",
    "        class_num: number of classes.\n",
    "        vocab_size: label name vocabulary size.\n",
    "        device: cuda or cpu.\n",
    "        load: load saved model weights or not.\n",
    "    \"\"\"\n",
    "\n",
    "    #enc.eval()\n",
    "    #dec.eval()\n",
    "    #enc.cpu()\n",
    "    #dec.cpu()\n",
    "    #enc.eval()\n",
    "    #quantized_enc = torch.quantization.convert(enc, inplace=False)\n",
    "    #print(\"enc Model converted to quantized version\")\n",
    "\n",
    "\n",
    "    #dec.eval()\n",
    "    #quantized_dec = torch.quantization.convert(dec, inplace=False)\n",
    "    #print(\"dec Model converted to quantized version\")\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    #print( opt )\n",
    "    #print(enc.weight.device)  # Should print 'cuda:0' if on GPU\n",
    "    #print(dec.weight.device)  # Should print 'cuda:0' if on GPU\n",
    "    enc.to(device)\n",
    "    dec.to(device)\n",
    "    print(next(enc.parameters()).device)\n",
    "    print(next(dec.parameters()).device)\n",
    "    print(enc.layer1.weight.device)\n",
    "    #quantized_enc.eval()\n",
    "    #quantized_dec.eval()\n",
    "    #quantized_enc.to(device)\n",
    "    #quantized_dec.to(device)\n",
    "    \n",
    "    if load:\n",
    "        enc = torch.load(os.path.join('model', f\"{opt['run_tag']}_enc.pth\"))\n",
    "        dec = torch.load(os.path.join('model', f\"{opt['run_tag']}_dec.pth\"))\n",
    "        #enc.load_state_dict(torch.load(opt['model_path'] + opt['run_tag'] + '_enc.pth', map_location=device, weights_only=False))\n",
    "        #dec.load_state_dict(torch.load(opt['model_path'] + opt['run_tag'] + '_dec.pth', map_location=device, weights_only=False))\n",
    "\n",
    "    hypotheses = list()\n",
    "    batch_size = test_data.size(0)\n",
    "    pred_whole = torch.zeros_like(test_label)\n",
    "    seqs = seqs.to(device)\n",
    "\n",
    "    total_evaluation_time = 0  # Initialize total evaluation time\n",
    "    total_samples = 0  # Initialize total number of samples\n",
    "\n",
    "    for batch_idx, (batch_data, batch_label, batch_text, batch_len) in enumerate(\n",
    "        DataBatch(test_data, test_label, test_text, test_len_text, opt['batchSize'], shuffle=False)\n",
    "    ):\n",
    "\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_label = batch_label.to(device)\n",
    "        batch_text = batch_text.to(device)\n",
    "        batch_len = batch_len.to(device)\n",
    "        batch_data = batch_data.to_mkldnn()\n",
    "        enc = enc.to_mkldnn()\n",
    "        # Start timing after sending to device\n",
    "        \n",
    "\n",
    "        batch_size = batch_data.size(0)\n",
    "        total_samples += batch_size  # Accumulate the number of samples\n",
    "        start_time = time.time()\n",
    "        encoder_out = enc(batch_data)  # (batch_size, enc_seq_len, encoder_dim)\n",
    "        enc_seq_len = encoder_out.size(1)\n",
    "        encoder_dim = encoder_out.size(2)\n",
    "\n",
    "        encoder_out = encoder_out.unsqueeze(1).expand(batch_size, class_num, enc_seq_len, encoder_dim)\n",
    "        encoder_out = encoder_out.reshape(batch_size * class_num, enc_seq_len, encoder_dim)\n",
    "\n",
    "        k_prev_words = seqs[:, 0].unsqueeze(0).expand(batch_size, class_num).long()  # (batch_size, class_num)\n",
    "        k_prev_words = k_prev_words.reshape(batch_size * class_num, 1)  # (batch_size * class_num, 1)\n",
    "\n",
    "        h, c = dec.init_hidden_state(encoder_out)\n",
    "\n",
    "        seq_scores = torch.zeros((batch_size, class_num)).to(device)\n",
    "\n",
    "        for step in range(1, break_step):\n",
    "            embeddings = dec.embedding(k_prev_words).squeeze(1)  # (batch_size * class_num, embed_dim)\n",
    "            h, c = dec.decode_step(embeddings, (h, c))\n",
    "            scores = dec.fc(h.reshape(batch_size, class_num, -1))  # (batch_size, class_num, vocab_size)\n",
    "            scores = F.log_softmax(scores, dim=-1)\n",
    "            k_prev_words = seqs[:, step].unsqueeze(0).expand(batch_size, class_num).long()\n",
    "            for batch_i in range(batch_size):\n",
    "                for class_i in range(class_num):\n",
    "                    if k_prev_words[batch_i, class_i] != 0:\n",
    "                        seq_scores[batch_i, class_i] += scores[batch_i, class_i, k_prev_words[batch_i, class_i]]\n",
    "            k_prev_words = k_prev_words.reshape(batch_size * class_num, 1)  # (batch_size * class_num, 1)\n",
    "\n",
    "        max_indices = seq_scores.argmax(dim=1)\n",
    "        for batch_i in range(batch_size):\n",
    "            max_i = max_indices[batch_i]\n",
    "            seq = seqs[max_i].tolist()\n",
    "            hypotheses.append([w for w in seq if w not in {0, vocab_size - 1}])\n",
    "            pred_whole[batch_i + batch_idx * opt['batchSize']] = pred_dict[\"#\".join(map(str, hypotheses[-1]))]\n",
    "\n",
    "        # End timing for the batch\n",
    "        end_time = time.time()\n",
    "        batch_evaluation_time = end_time - start_time  # Calculate batch evaluation time\n",
    "        total_evaluation_time += batch_evaluation_time  # Accumulate total evaluation time\n",
    "\n",
    "        print(f'Batch {batch_idx + 1} Evaluation Time: {batch_evaluation_time:.2f} seconds')\n",
    "\n",
    "    acc = accuracy_score(test_label.cpu().numpy(), pred_whole.cpu().numpy())\n",
    "    prec = precision_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "    rec = recall_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "    f1 = f1_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "\n",
    "    print(f'Total Evaluation Time: {total_evaluation_time:.2f} seconds')\n",
    "    \n",
    "    # Calculate evaluation time per batch and per sample\n",
    "    eval_time_per_batch = total_evaluation_time / (batch_idx + 1)\n",
    "    eval_time_per_sample = total_evaluation_time / total_samples\n",
    "\n",
    "    print(f'Average Evaluation Time per Batch: {eval_time_per_batch:.2f} seconds')\n",
    "    print(f'Average Evaluation Time per Sample: {eval_time_per_sample:.6f} seconds')\n",
    "\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.quantization\n",
    "\n",
    "import semantichar.data \n",
    "from semantichar import imagebind_model\n",
    "from semantichar.imagebind_model import ModalityType\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.quantization as quant\n",
    "class CustomBatchNorm1d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomBatchNorm1d, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert batch normalization to quantization-aware operations\n",
    "        if self.training:\n",
    "            x = self.bn(x)\n",
    "        else:\n",
    "            x = torch.nn.functional.batch_norm(\n",
    "                x, \n",
    "                self.bn.running_mean, \n",
    "                self.bn.running_var, \n",
    "                self.bn.weight, \n",
    "                self.bn.bias, \n",
    "                training=False\n",
    "            )\n",
    "        return x\n",
    "    \n",
    "\n",
    "class QuantizedLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, bias=True):\n",
    "        super(QuantizedLinear, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)  # Quantize input\n",
    "        x = self.fc(x)     # Apply linear transformation\n",
    "        x = self.dequant(x)  # Dequantize output\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        # Fuse the linear layer with the quantization stubs\n",
    "        torch.quantization.fuse_modules(self, ['quant', 'fc', 'dequant'], inplace=True)\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.fc.weight\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self.fc.bias\n",
    " \n",
    "    \n",
    "class CustomObserver(quant.MinMaxObserver):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomObserver, self).__init__(*args, **kwargs)\n",
    "\n",
    "class QuantizedConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
    "        super(QuantizedConv1d, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.weight_fake_quant = quant.FakeQuantize.with_args(observer=quant.default_weight_observer, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_affine)()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)  # Quantize input\n",
    "        x = self.conv(x)   # Apply convolution\n",
    "        x = self.bn(x)     # Apply batch normalization\n",
    "        x = self.relu(x)   # Apply ReLU\n",
    "        x = self.dequant(x)  # Dequantize output\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        # Fuse the conv, batch norm, and ReLU layers\n",
    "        torch.quantization.fuse_modules(self, [['conv', 'bn', 'relu']], inplace=True)\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.conv.weight\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self.conv.bias\n",
    "\n",
    "    def apply_weight_fake_quant(self):\n",
    "        self.weight_fake_quant(self.conv.weight)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_input: int,\n",
    "                 d_model: int,\n",
    "                 d_output: int,\n",
    "                 seq_len: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Conv1d(in_channels=d_input, out_channels=d_model, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(d_model)\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.layer2 = nn.Conv1d(in_channels=d_model, out_channels=d_output, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(d_model)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b,t,c = x.size()\n",
    "\n",
    "        out = self.layer1(x.permute(0,2,1))\n",
    "        #out = self.act1((out))\n",
    "        out = self.act1(self.bn1(out))\n",
    "\n",
    "        out = self.layer2(out)\n",
    "        #out = self.act2(out)\n",
    "        out = self.act2(self.bn2(out)) # (b, d_output, seq_len)\n",
    "\n",
    "        return out.permute(0,2,1) # (b, seq_len, d_output)\n",
    "        \n",
    "class Encoder_q(nn.Module):\n",
    "    def __init__(self, d_input: int, d_model: int, d_output: int, seq_len: int):\n",
    "        super().__init__()\n",
    "        self.layer1 = QuantizedConv1d(in_channels=d_input, out_channels=d_model, kernel_size=3, padding=1)\n",
    "        self.layer2 = QuantizedConv1d(in_channels=d_model, out_channels=d_output, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, t, c = x.size()\n",
    "        out = self.layer1(x.permute(0, 2, 1))\n",
    "        self.layer1.apply_weight_fake_quant()  # Apply weight fake quantization for layer1\n",
    "        out = self.layer2(out)\n",
    "        self.layer2.apply_weight_fake_quant()  # Apply weight fake quantization for layer2\n",
    "        out = out.permute(0, 2, 1)  # (b, seq_len, d_output)\n",
    "        return out\n",
    "\n",
    "class QuantizedLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(QuantizedLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        self.ih = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "        self.hh = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "\n",
    "        self.quant1 = QuantStub()\n",
    "        self.dequant1 = DeQuantStub()\n",
    "\n",
    "        self.quant2 = QuantStub()\n",
    "        self.dequant2 = DeQuantStub()\n",
    "\n",
    "        self.quant3 = QuantStub()\n",
    "        self.dequant3 = DeQuantStub()\n",
    "\n",
    "\n",
    "    def forward(self, input, hx):\n",
    "        hx, cx = hx\n",
    "\n",
    "        # Quantize inputs\n",
    "        #input = self.quant1(input)\n",
    "        hx = self.quant2(hx)\n",
    "        cx = self.quant3(cx)\n",
    "\n",
    "        # LSTM cell operations\n",
    "        ih_out = self.ih(input)\n",
    "        hh_out = self.hh(hx)\n",
    "\n",
    "        # Dequantize before addition and multiplication\n",
    "        #ih_out = self.dequant1(ih_out)\n",
    "        hh_out = self.dequant2(hh_out)\n",
    "        cx = self.dequant3(cx)\n",
    "\n",
    "        gates = ih_out + hh_out\n",
    "\n",
    "        i, f, g, o = gates.chunk(4, 1)\n",
    "\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        g = torch.tanh(g)\n",
    "        o = torch.sigmoid(o)\n",
    "\n",
    "        cy = f * cx + i * g\n",
    "        hy = o * torch.tanh(cy)\n",
    "\n",
    "        return hy, cy\n",
    "\n",
    "    def _init_hidden(self, batch_size, device):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(batch_size, self.hidden_size).zero_().to(device),\n",
    "                weight.new(batch_size, self.hidden_size).zero_().to(device))\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim, decoder_dim, vocab, encoder_dim, device, dropout=0.5):\n",
    "      \n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, embed_dim)  \n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.decode_step = nn.LSTMCell(embed_dim, decoder_dim, bias=True)  \n",
    "        self.init_h = nn.Linear(encoder_dim, decoder_dim)  \n",
    "        self.init_c = nn.Linear(encoder_dim, decoder_dim)  \n",
    "        self.fc = nn.Linear(decoder_dim, self.vocab_size) \n",
    "        self.load_pretrained_embeddings()\n",
    "\n",
    "    def load_pretrained_embeddings(self):\n",
    "\n",
    "        inputs = {\n",
    "            ModalityType.TEXT: semantichar.data.load_and_transform_text(self.vocab, self.device)\n",
    "        }\n",
    "        model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "        model.eval()\n",
    "        model.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(inputs)['text']\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def init_hidden_state(self, encoder_out):\n",
    "        \n",
    "        mean_encoder_out = encoder_out.mean(dim=1) \n",
    "        h = self.init_h(mean_encoder_out) \n",
    "        c = self.init_c(mean_encoder_out)\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
    "        \n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  \n",
    "        seq_len = encoder_out.size(1)\n",
    "\n",
    "        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim=0, descending=True)\n",
    "        encoder_out = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "\n",
    "        embeddings = self.embedding(encoded_captions.long()) \n",
    "\n",
    "        h, c = self.init_hidden_state(encoder_out)  \n",
    "\n",
    "        decode_lengths = (caption_lengths - 1).tolist()\n",
    "        \n",
    "        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(self.device)\n",
    "\n",
    "        for t in range(max(decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in decode_lengths]) \n",
    "            h, c = self.decode_step(embeddings[:batch_size_t, t, :], \\\n",
    "                (h[:batch_size_t], c[:batch_size_t]))\n",
    "            preds = self.fc(self.dropout(h))  \n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "        return predictions, encoded_captions, decode_lengths, sort_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.quantization as quant\n",
    "from torch.quantization.observer import MovingAverageMinMaxObserver, default_weight_observer\n",
    "\n",
    "#from semantichar.seq2seq import Encoder, Decoder\n",
    "#from semantichar.exp import trainer, evaluate\n",
    "from semantichar.dataset import prepare_dataset\n",
    "\n",
    "class CustomObserver(MovingAverageMinMaxObserver):\n",
    "    def calculate_qparams(self):\n",
    "        scale, _ = super().calculate_qparams()\n",
    "        zero_point = torch.tensor(0, dtype=torch.int32)\n",
    "        return scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keerthiv/HAR_models/share/share_rasppi/SHARE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keerthiv/.local/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: easy_imu_phone\n",
      "data_path: ./\n",
      "manualSeed: 2023\n",
      "epochs: 150\n",
      "early_stopping: 50\n",
      "batchSize: 16\n",
      "lr: 0.0001\n",
      "prob: 0.4\n",
      "cuda: True\n",
      "run_tag: test\n",
      "model_path: ./model/\n",
      "Random Seed:  2023\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "# Updated values for the arguments\n",
    "dataset = 'easy_imu_phone'\n",
    "data_path = './'\n",
    "manualSeed = 2023\n",
    "epochs = 150\n",
    "early_stopping = 50\n",
    "batchSize = 16\n",
    "lr = 1e-4\n",
    "prob = 0.4\n",
    "cuda = True\n",
    "run_tag = 'test'\n",
    "model_path = './model/'\n",
    "\n",
    "# Print the updated values\n",
    "print(f'dataset: {dataset}')\n",
    "print(f'data_path: {data_path}')\n",
    "print(f'manualSeed: {manualSeed}')\n",
    "print(f'epochs: {epochs}')\n",
    "print(f'early_stopping: {early_stopping}')\n",
    "print(f'batchSize: {batchSize}')\n",
    "print(f'lr: {lr}')\n",
    "print(f'prob: {prob}')\n",
    "print(f'cuda: {cuda}')\n",
    "print(f'run_tag: {run_tag}')\n",
    "print(f'model_path: {model_path}')\n",
    "\n",
    "# Set random seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not cuda:\n",
    "    print(\"You have a cuda device, so you might want to run with --cuda as option\")\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "data_root = data_path + '/dataset/' + dataset\n",
    "config_file = data_path + '/configs/' + dataset + '.json'\n",
    "with open(config_file, 'r') as config_file:\n",
    "    data = json.load(config_file)\n",
    "    label_dictionary = {int(k): v for k, v in data['label_dictionary'].items()}\n",
    "\n",
    "tr_data = np.load(data_root + '/x_train.npy')\n",
    "tr_label = np.load(data_root + '/y_train.npy')\n",
    "\n",
    "test_data = np.load(data_root + '/x_test.npy')\n",
    "test_label = np.load(data_root + '/y_test.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(2)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(5)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(6)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(7)\n",
      "tensor(6)\n",
      "tensor(8)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(7)\n",
      "tensor(4)\n",
      "tensor(8)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(9)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(10)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(11)\n",
      "tensor(12)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(13)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(14)\n",
      "tensor(6)\n",
      "tensor(15)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(14)\n",
      "tensor(4)\n",
      "tensor(15)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(16)\n",
      "tensor(17)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(18)\n",
      "tensor(19)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(20)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(21)\n",
      "tensor(22)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(23)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(24)\n",
      "tensor(25)\n",
      "tensor(26)\n",
      "tensor(1)\n",
      "tensor(27)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(24)\n",
      "tensor(25)\n",
      "tensor(26)\n",
      "tensor(5)\n",
      "tensor(27)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(28)\n",
      "tensor(29)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(30)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(31)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(6)\n",
      "tensor(8)\n",
      "tensor(32)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(4)\n",
      "tensor(8)\n",
      "tensor(32)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(33)\n",
      "tensor(34)\n",
      "tensor(36)\n",
      "tensor(0)\n",
      "tensor(33)\n",
      "tensor(35)\n",
      "tensor(34)\n",
      "tensor(36)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "seq_len, dim, class_num, vocab_size, break_step, word_list, pred_dict, seqs, \\\n",
    "    tr_data, test_data, \\\n",
    "    tr_label, test_label, \\\n",
    "    tr_text, test_text, \\\n",
    "    len_text, test_len_text = prepare_dataset(tr_data, tr_label, test_data, test_label, label_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'standing', 'walking', 'turning', 'left', 'sitting', 'right', 'waving', 'hand', 'jumping', 'lying', 'drinking', 'water', 'throwing', 'kicking', 'foot', 'golf', 'swinging', 'basketball', 'shooting', 'boxing', 'torso', 'twisting', 'squatting', 'forward', 'bending', 'in', 'position', 'leg', 'stretching', 'pushing', 'pulling', 'up', 'drawing', 'clockwise', 'counter', 'end']\n"
     ]
    }
   ],
   "source": [
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomObserver(MovingAverageMinMaxObserver):\n",
    "    def calculate_qparams(self):\n",
    "        scale, _ = super().calculate_qparams()\n",
    "        zero_point = torch.tensor(0, dtype=torch.int32)\n",
    "        return scale, zero_point\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "enc = Encoder(d_input=dim, d_model=128, d_output=128, seq_len=seq_len).to(device)\n",
    "dec = Decoder(embed_dim=1024, decoder_dim=128, vocab=word_list, encoder_dim=128, device=device).to(device)\n",
    "\n",
    "# Apply the quantization configuration to the embedding layers in the decoder\n",
    "enc.train()\n",
    "dec.train()\n",
    "\n",
    "# Move the models to GPU for training\n",
    "enc.to(device)\n",
    "dec.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "params = list(enc.parameters()) + list(dec.parameters())\n",
    "optimizer = optim.Adam(params, lr=1e-4)\n",
    "cross_entropy = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batchSize': batchSize,\n",
    "    'epochs': epochs,\n",
    "    'run_tag': run_tag,\n",
    "    'dataset': dataset,\n",
    "    'cuda': cuda,\n",
    "    'manualSeed': manualSeed,\n",
    "    'data_path': data_path,\n",
    "    'early_stopping': early_stopping,\n",
    "    'lr': 0.0001,\n",
    "    'prob': prob,\n",
    "    'model_path': model_path\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1, 36,  0,  0,  0,  0],\n",
      "        [ 0,  2, 36,  0,  0,  0,  0],\n",
      "        [ 0,  3,  4, 36,  0,  0,  0],\n",
      "        [ 0,  5, 36,  0,  0,  0,  0],\n",
      "        [ 0,  3,  6, 36,  0,  0,  0],\n",
      "        [ 0,  7,  6,  8, 36,  0,  0],\n",
      "        [ 0,  7,  4,  8, 36,  0,  0],\n",
      "        [ 0,  9, 36,  0,  0,  0,  0],\n",
      "        [ 0, 10, 36,  0,  0,  0,  0],\n",
      "        [ 0, 11, 12, 36,  0,  0,  0],\n",
      "        [ 0, 13, 36,  0,  0,  0,  0],\n",
      "        [ 0, 14,  6, 15, 36,  0,  0],\n",
      "        [ 0, 14,  4, 15, 36,  0,  0],\n",
      "        [ 0, 16, 17, 36,  0,  0,  0],\n",
      "        [ 0, 18, 19, 36,  0,  0,  0],\n",
      "        [ 0, 20, 36,  0,  0,  0,  0],\n",
      "        [ 0, 21, 22, 36,  0,  0,  0],\n",
      "        [ 0, 23, 36,  0,  0,  0,  0],\n",
      "        [ 0, 24, 25, 26,  1, 27, 36],\n",
      "        [ 0, 24, 25, 26,  5, 27, 36],\n",
      "        [ 0, 28, 29, 36,  0,  0,  0],\n",
      "        [ 0, 30, 36,  0,  0,  0,  0],\n",
      "        [ 0, 31, 36,  0,  0,  0,  0],\n",
      "        [ 0,  6,  8, 32, 36,  0,  0],\n",
      "        [ 0,  4,  8, 32, 36,  0,  0],\n",
      "        [ 0, 33, 34, 36,  0,  0,  0],\n",
      "        [ 0, 33, 35, 34, 36,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "enc.to(device)\n",
    "dec.to(device)\n",
    "tr_data.to(device)\n",
    "tr_label.to(device)\n",
    "tr_text.to(device)\n",
    "len_text.to(device)\n",
    "\n",
    "for epoch in range(300):\n",
    "    loss = trainer(\n",
    "        config, # configs\n",
    "        enc, # encoder\n",
    "        dec, # decoder\n",
    "        cross_entropy, # loss\n",
    "        optimizer, # optimizer\n",
    "        tr_data, # training input\n",
    "        tr_label, # training labels\n",
    "        tr_text, # training label text sequence\n",
    "        len_text, # training label text sequence length\n",
    "        break_step, # max training label text sequence length\n",
    "        vocab_size, # vocabulary size\n",
    "        device, # device\n",
    "    )\n",
    "\n",
    "    print(\"epoch: %d total loss: %.4f\" % (epoch + 1, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(enc.state_dict(), model_path + run_tag + '_enc.pth')\n",
    "torch.save(dec.state_dict(), model_path + run_tag + '_dec.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(37, 1024)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (decode_step): LSTMCell(1024, 128)\n",
       "  (init_h): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (init_c): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc): Linear(in_features=128, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "enc = Encoder(d_input=dim, d_model=128, d_output=128, seq_len=seq_len)\n",
    "dec = Decoder(embed_dim=1024, decoder_dim=128, vocab=word_list, encoder_dim=128, device=device)\n",
    "\n",
    "# Assuming 'config' is a dictionary containing 'run_tag'\n",
    "enc_load_path = os.path.join('model', f\"{config['run_tag']}_enc.pth\")\n",
    "dec_load_path = os.path.join('model', f\"{config['run_tag']}_dec.pth\")\n",
    "\n",
    "# Load the state dictionary from the file\n",
    "enc_state_dict = torch.load(enc_load_path)\n",
    "dec_state_dict = torch.load(dec_load_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "enc.load_state_dict(enc_state_dict)\n",
    "dec.load_state_dict(dec_state_dict)\n",
    "\n",
    "# Ensure the models are on the correct device\n",
    "enc.to(device)\n",
    "dec.to(device)\n",
    "#seqs = torch.load('seqs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320\n",
      "Test Acc: 0.9326 Macro-Prec: 0.9468 Macro-Rec: 0.9326 Macro-F1: 0.9315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#enc.to(device)\n",
    "#dec.to(device)\n",
    "enc.eval()\n",
    "dec.eval()\n",
    "\n",
    "hypotheses = list()\n",
    "batch_size = test_data.size(0)\n",
    "pred_whole = torch.zeros_like(test_label)\n",
    "seqs = seqs.to(device)\n",
    "#print(seqs)\n",
    "config['batchSize'] = 16\n",
    "total_evaluation_time = 0  # Initialize total evaluation time\n",
    "total_samples = 0  # Initialize total number of samples\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inds, batch_data, batch_label, batch_text, batch_len) in enumerate(\n",
    "            DataBatch(test_data, test_label, test_text, test_len_text, config['batchSize'] , shuffle=True)\n",
    "        ):\n",
    "            #pred_whole = torch.zeros_like(test_label)\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_label = batch_label.to(device)\n",
    "            batch_text = batch_text.to(device)\n",
    "            batch_len = batch_len.to(device)\n",
    "            #print( batch_idx )\n",
    "            #print( inds)\n",
    "            \n",
    "\n",
    "            batch_size = batch_data.size(0)\n",
    "            \n",
    "            total_samples += batch_size  # Accumulate the number of samples\n",
    "            start_time = time.time()\n",
    "            #print(enc.layer1.weight.device)\n",
    "            #print(batch_data.device)\n",
    "            #print(dec.init_h.weight.device)\n",
    "            encoder_out = enc(batch_data)  # (batch_size, enc_seq_len, encoder_dim)\n",
    "            #print(encoder_out.shape)\n",
    "            enc_seq_len = encoder_out.size(1)\n",
    "            encoder_dim = encoder_out.size(2)\n",
    "\n",
    "            encoder_out = encoder_out.unsqueeze(1).expand(batch_size, class_num, enc_seq_len, encoder_dim)\n",
    "            encoder_out = encoder_out.reshape(batch_size * class_num, enc_seq_len, encoder_dim)\n",
    "            #print(seqs)\n",
    "            k_prev_words = seqs[:, 0].unsqueeze(0).expand(batch_size, class_num).long()  # (batch_size, class_num)\n",
    "            #print(k_prev_words)\n",
    "            k_prev_words = k_prev_words.reshape(batch_size * class_num, 1)  # (batch_size * class_num, 1)\n",
    "            \n",
    "            h, c = dec.init_hidden_state(encoder_out)\n",
    "\n",
    "            seq_scores = torch.zeros((batch_size, class_num)).to(device)\n",
    "\n",
    "            for step in range(1, break_step):\n",
    "                embeddings = dec.embedding(k_prev_words).squeeze(1)  # (batch_size * class_num, embed_dim)\n",
    "                h, c = dec.decode_step(embeddings, (h, c))\n",
    "                scores = dec.fc(h.reshape(batch_size, class_num, -1))  # (batch_size, class_num, vocab_size)\n",
    "                scores = F.log_softmax(scores, dim=-1)\n",
    "                k_prev_words = seqs[:, step].unsqueeze(0).expand(batch_size, class_num).long()\n",
    "                for batch_i in range(batch_size):\n",
    "                    for class_i in range(class_num):\n",
    "                        if k_prev_words[batch_i, class_i] != 0:\n",
    "                            seq_scores[batch_i, class_i] += scores[batch_i, class_i, k_prev_words[batch_i, class_i]]\n",
    "                k_prev_words = k_prev_words.reshape(batch_size * class_num, 1)  # (batch_size * class_num, 1)\n",
    "            #print( seq_scores )\n",
    "            max_indices = seq_scores.argmax(dim=1)\n",
    "            for batch_i in range(batch_size):\n",
    "                max_i = max_indices[batch_i]\n",
    "                seq = seqs[max_i].tolist()\n",
    "                hypotheses.append([w for w in seq if w not in {0, vocab_size - 1}])\n",
    "                #print(batch_i + batch_idx * config['batchSize'])\n",
    "                #pred_whole[batch_i + batch_idx * config['batchSize']] = pred_dict[\"#\".join(map(str, hypotheses[-1]))]\n",
    "                #print(batch_i + batch_idx * config['batchSize'])\n",
    "                #print\n",
    "                pred_whole[inds[batch_i]] = pred_dict[\"#\".join(map(str, hypotheses[-1]))]\n",
    "                #print(test_label[inds[batch_i]])\n",
    "                #print( pred_whole[inds[batch_i]] )\n",
    "            #print( pred_whole.shape)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            batch_evaluation_time = end_time - start_time  # Calculate batch evaluation time\n",
    "            total_evaluation_time += batch_evaluation_time  # Accumulate total evaluation time\n",
    "\n",
    "            #acc = accuracy_score(test_label.cpu().numpy(), pred_whole.cpu().numpy())\n",
    "            #prec = precision_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "            #rec = recall_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "            #f1 = f1_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "\n",
    "            #print(f'Total Evaluation Time: {total_evaluation_time:.2f} seconds')\n",
    "    \n",
    "            # Calculate evaluation time per batch and per sample\n",
    "            #eval_time_per_batch = total_evaluation_time / (batch_idx + 1)\n",
    "            #eval_time_per_sample = total_evaluation_time / total_samples\n",
    "\n",
    "            #print(f'Average Evaluation Time per Batch: {eval_time_per_batch:.2f} seconds')\n",
    "            #print(f'Average Evaluation Time per Sample: {eval_time_per_sample:.6f} seconds')\n",
    "            #print('Test Acc: %.4f Macro-Prec: %.4f Macro-Rec: %.4f Macro-F1: %.4f' % (acc, prec, rec, f1))\n",
    "\n",
    "            #print(f'Batch {batch_idx + 1} Evaluation Time: {batch_evaluation_time:.2f} seconds')\n",
    "#print( pred_whole.shape )\n",
    "#print( test_label.shape )\n",
    "\n",
    "acc = accuracy_score(test_label.cpu().numpy(), pred_whole.cpu().numpy())\n",
    "prec = precision_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "rec = recall_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "f1 = f1_score(test_label.cpu().numpy(), pred_whole.cpu().numpy(), average='macro', zero_division=0)\n",
    "\n",
    "#print(f'Total Evaluation Time: {total_evaluation_time:.2f} seconds')\n",
    "    \n",
    "    # Calculate evaluation time per batch and per sample\n",
    "#eval_time_per_batch = total_evaluation_time / (batch_idx + 1)\n",
    "#eval_time_per_sample = total_evaluation_time / total_samples\n",
    "\n",
    "#print(f'Average Evaluation Time per Batch: {eval_time_per_batch:.2f} seconds')\n",
    "#print(f'Average Evaluation Time per Sample: {eval_time_per_sample:.6f} seconds')\n",
    "print('Test Acc: %.4f Macro-Prec: %.4f Macro-Rec: %.4f Macro-F1: %.4f' % (acc, prec, rec, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
